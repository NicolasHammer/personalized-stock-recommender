{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Personalized Stock Recommender Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from src import mf_bpr, als, word2vec, metrics, datasets, utils"
   ]
  },
  {
   "source": [
    "## Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_dummy():\n",
    "    dummy_data = pd.read_csv(\"data/dummy.data\", sep='\\t', names = ['user_id', 'item_id',\n",
    "        'rating', 'timestamp'], engine = \"python\")\n",
    "    num_users = dummy_data.user_id.unique().shape[0]\n",
    "    num_items = dummy_data.item_id.unique().shape[0]\n",
    "    return dummy_data, num_users, num_items"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_uci():\n",
    "    # Read data\n",
    "    uci_data = pd.read_excel(\"data/data_UCI.xlsx\", header = 0, engine = \"openpyxl\")\n",
    "\n",
    "    # Massage data\n",
    "    uci_data = uci_data[pd.isnull(uci_data[\"investor_id\"]) == False]\n",
    "    uci_data = uci_data.drop_duplicates(subset = [\"investor_id\", \"stock_id\"])\n",
    "\n",
    "    v = uci_data[\"investor_id\"].value_counts()\n",
    "    uci_data = uci_data[uci_data[\"investor_id\"].isin(v.index[v.gt(20)])]\n",
    "\n",
    "    uci_data[\"investor_id\"], _ = pd.factorize(uci_data[\"investor_id\"])\n",
    "    uci_data[\"stock_id\"], _ = pd.factorize(uci_data[\"stock_id\"])\n",
    "\n",
    "    num_investors = uci_data.investor_id.unique().shape[0]\n",
    "    num_stocks = uci_data.stock_id.unique().shape[0]\n",
    "    return uci_data, num_investors, num_stocks"
   ]
  },
  {
   "source": [
    "## Matrix Factorization with BPR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_bpr(net, test_input, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "        test_dataset = data.TensorDataset(torch.from_numpy(np.array(user_ids)),    \n",
    "            torch.from_numpy(np.array(item_ids)))\n",
    "        test_data_iter = data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "\n",
    "        for _, (user_idxs, item_idxs) in enumerate(test_data_iter):\n",
    "            scores.extend(list(net(user_idxs, item_idxs).detach().numpy()))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "        temp = metrics.hit_and_auc(ranked_items[u], test_input[u][0], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "#### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_bpr(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "        if u not in test_items or test_items[u][2] < time:\n",
    "            test_items[u] = (i, rating, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(1, num_users + 1):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[3])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_dummy_bpr(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "train_dummy, test_dummy = train_test_dummy_bpr(dummy_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_dummy_bpr(train_dummy,    \n",
    "    num_users, num_items)\n",
    "train_dummy_dataset = datasets.PairwiseDataset(np.array(train_users), np.array(train_items),\n",
    "    interactions, num_items)\n",
    "train_dataloader = data.DataLoader(dataset = train_dummy_dataset, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_dummy_bpr(test_dummy, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd, latent_factors = 0.01, 20, 1e-5, 10\n",
    "\n",
    "bpr_net = mf_bpr.MF_BPR(num_users, num_items, latent_factors) \n",
    "loss = mf_bpr.BPR_Loss\n",
    "optimizer = optim.Adam(bpr_net.parameters(), lr = 0.01, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_bpr = []\n",
    "auc_list_bpr = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    bpr_net.train()\n",
    "    for i, (user_idxs, item_idxs, neg_items) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p_pos = bpr_net(user_idxs, item_idxs)\n",
    "        p_neg = bpr_net(user_idxs, neg_items)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    bpr_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(bpr_net, test_interactions, interactions, num_users,   \n",
    "        num_items)\n",
    "    hit_rate_list_bpr.append(hit_rate)\n",
    "    auc_list_bpr.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "%matplotlib qt\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_bpr, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_bpr, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of MF\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_bpr(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, time = line[1], line[2], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, time))\n",
    "        if u not in test_items or test_items[u][1] < time:\n",
    "            test_items[u] = (i, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(0, num_users):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[2])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_uci_bpr(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = line[1], line[2]\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "train_uci, test_uci = train_test_uci_bpr(uci_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_uci_bpr(train_uci,    \n",
    "    num_users, num_items)\n",
    "train_uci_dataset = datasets.PairwiseDataset(np.array(train_users), np.array(train_items),\n",
    "    interactions, num_items)\n",
    "train_dataloader = data.DataLoader(dataset = train_uci_dataset, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_uci_bpr(test_uci, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd, latent_factors = 0.01, 10, 1e-5, 10\n",
    "\n",
    "bpr_net = mf_bpr.MF_BPR(num_users, num_items, latent_factors) \n",
    "loss = mf_bpr.BPR_Loss\n",
    "optimizer = optim.Adam(bpr_net.parameters(), lr = 0.01, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_bpr = []\n",
    "auc_list_bpr = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    bpr_net.train()\n",
    "    for i, (user_idxs, item_idxs, neg_items) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p_pos = bpr_net(user_idxs, item_idxs)\n",
    "        p_neg = bpr_net(user_idxs, neg_items)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    bpr_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(bpr_net, test_interactions, interactions, num_users,   \n",
    "        num_items)\n",
    "    hit_rate_list_bpr.append(hit_rate)\n",
    "    auc_list_bpr.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "%matplotlib qt\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_bpr[0:10], label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_bpr[0:10], label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of MF\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Alternating Least Squares"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_als(net, test_input, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "\n",
    "        scores.extend(list(net.predict(user_ids, item_ids)))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "        temp = metrics.hit_and_auc(ranked_items[u], test_input[u][0], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_als(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "        if u not in test_items or test_items[u][2] < time:\n",
    "            test_items[u] = (i, rating, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(1, num_users + 1):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[3])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_dummy_als(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "train_dummy, test_dummy = train_test_dummy_als(dummy_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_dummy_als(train_dummy,    \n",
    "    num_users, num_items)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_dummy_als(test_dummy, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_epochs, reg, latent_factors = 20, 0.01, 30\n",
    "\n",
    "ratings_matrix = coo_matrix((train_ratings, (train_users, train_items)), shape = (num_users, \n",
    "    num_items)).todense()\n",
    "als_net = als.ALS(num_users, num_items, latent_factors, ratings_matrix, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_als = []\n",
    "auc_list_als = []\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    # Train with entire batch\n",
    "    als_net.train()\n",
    "\n",
    "    # Evaluate\n",
    "    hit_rate, auc = evaluate_ranking_als(als_net, test_interactions, interactions, num_users,\n",
    "        num_items)\n",
    "    hit_rate_list_als.append(hit_rate)\n",
    "    auc_list_als.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: hit_rate = {hit_rate}, auc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_als, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_als, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of ALS\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_als(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, time = line[1], line[2], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, time))\n",
    "        if u not in test_items or test_items[u][1] < time:\n",
    "            test_items[u] = (i, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(0, num_users):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[2])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uci_als(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = line[1], line[2]\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "train_uci, test_uci = train_test_uci_als(uci_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_uci_als(train_uci,    \n",
    "    num_users, num_items)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_uci_als(test_uci, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_epochs, reg, latent_factors = 10, 0.01, 30\n",
    "\n",
    "ratings_matrix = coo_matrix((train_ratings, (train_users, train_items)), shape = (num_users, \n",
    "    num_items)).todense()\n",
    "als_net = als.ALS(num_users, num_items, latent_factors, ratings_matrix, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: hit_rate = 0.10680592991913747, auc = 0.7275213597634397\n",
      "Epoch 1: hit_rate = 0.21900269541778974, auc = 0.8135537362983325\n",
      "Epoch 2: hit_rate = 0.23955525606469003, auc = 0.8256568351036048\n",
      "Epoch 3: hit_rate = 0.24494609164420486, auc = 0.8306512225513197\n",
      "Epoch 4: hit_rate = 0.24898921832884097, auc = 0.8333216937722749\n",
      "Epoch 5: hit_rate = 0.25101078167115903, auc = 0.8347824195050898\n",
      "Epoch 6: hit_rate = 0.2503369272237197, auc = 0.8359100352864707\n",
      "Epoch 7: hit_rate = 0.25168463611859837, auc = 0.8369317630113239\n",
      "Epoch 8: hit_rate = 0.2526954177897574, auc = 0.8372658158040569\n",
      "Epoch 9: hit_rate = 0.25235849056603776, auc = 0.8373635611716901\n",
      "Epoch 10: hit_rate = 0.25134770889487873, auc = 0.8372701048620707\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4b38bd3fae75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     hit_rate, auc = evaluate_ranking_als(als_net, test_interactions, interactions, num_users,\n\u001b[0m\u001b[1;32m     11\u001b[0m         num_items)\n\u001b[1;32m     12\u001b[0m     \u001b[0mhit_rate_list_als\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-86f8419922c5>\u001b[0m in \u001b[0;36mevaluate_ranking_als\u001b[0;34m(net, test_input, interactions, num_users, num_items)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mitem_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - Northwestern University/Documents/Winter 2021/Deep Learning/personalized_stock_recommender/src/als.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user_ids, item_idxs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mMake\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mALS\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_investor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_stock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_als = []\n",
    "auc_list_als = []\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    # Train with entire batch\n",
    "    als_net.train()\n",
    "\n",
    "    # Evaluate\n",
    "    hit_rate, auc = evaluate_ranking_als(als_net, test_interactions, interactions, num_users,\n",
    "        num_items)\n",
    "    hit_rate_list_als.append(hit_rate)\n",
    "    auc_list_als.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: hit_rate = {hit_rate}, auc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Visualize\n",
    "%matplotlib qt\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_als[0:10], label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_als[0:10], label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of ALS\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_cbow(net, test_targets, test_contexts, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    item_ids = list(range(num_items))\n",
    "    \n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader_test):\n",
    "        scores = net(contexts).tolist()\n",
    "        for u, row in enumerate(scores):\n",
    "            item_scores = list(zip(item_ids, row))\n",
    "            ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "            ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "            temp = metrics.hit_and_auc(ranked_items[u], test_targets[u], 50)\n",
    "            hit_rate.append(temp[0])\n",
    "            auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep interactions\n",
    "def load_interactions_cbow(dummy_data : pd.DataFrame):\n",
    "    interactions = {}\n",
    "    for line in dummy_data.itertuples():\n",
    "        user_index, item_index, time = line[1] - 1, line[2] - 1, line[4]\n",
    "        interactions.setdefault(user_index, []).append((item_index, time))\n",
    "\n",
    "    interactions = {k : sorted(v, key = (lambda pair : pair[1])) for k, v in interactions.items()}\n",
    "    return {k : [x[0] for x in v] for k, v in interactions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_cbow(interactions : dict, window : int):\n",
    "    train_targets, train_contexts = [], []\n",
    "    test_targets, test_contexts = [], []\n",
    "\n",
    "    # Iterate through every interaction\n",
    "    for user_interactions in interactions.values():\n",
    "        num_interactions = len(user_interactions)\n",
    "        # Add to training data\n",
    "        for i in range(window, num_interactions - 1):\n",
    "            train_targets.append(user_interactions[i])\n",
    "            train_contexts.append([user_interactions[j] for j in np.arange(i - window, i)])\n",
    "        # Add to testing data\n",
    "        test_targets.append(user_interactions[num_interactions - 1])\n",
    "        test_contexts.append([user_interactions[j] for j \n",
    "            in np.arange(num_interactions - 1 - window, num_interactions - 1)])\n",
    "        \n",
    "    return train_targets, train_contexts, test_targets, test_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "window = 10\n",
    "\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "sorted_interactions = load_interactions_cbow(dummy_data)\n",
    "train_targets, train_contexts, test_targets, test_contexts = train_test_dummy_cbow(sorted_interactions, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and model\n",
    "ngrams_train = data.TensorDataset(torch.from_numpy(np.array(train_targets)), \n",
    "        torch.from_numpy(np.array(train_contexts)))\n",
    "ngrams_dataloader = data.DataLoader(dataset = ngrams_train, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "ngrams_test = data.TensorDataset(torch.from_numpy(np.array(test_targets)), \n",
    "    torch.from_numpy(np.array(test_contexts)))\n",
    "ngrams_dataloader_test = data.DataLoader(dataset = ngrams_test, batch_size = 1024, \n",
    "    shuffle = False, num_workers = 4)\n",
    "\n",
    "embedding_dim, num_epochs, learning_rate = 30, 20, 0.025\n",
    "loss = torch.nn.NLLLoss()\n",
    "cbow_net = word2vec.CBOW(num_items, embedding_dim, window)\n",
    "optimizer = optim.Adam(cbow_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_cbow = []\n",
    "auc_list_cbow = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    cbow_net.train()\n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_probabilities = cbow_net(contexts)\n",
    "\n",
    "        total_loss = loss(log_probabilities, targets)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, targets.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    cbow_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_cbow(cbow_net, test_targets, test_contexts, num_items)\n",
    "    hit_rate_list_cbow.append(hit_rate)\n",
    "    auc_list_cbow.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_cbow, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_cbow, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of CBOW\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep interactions\n",
    "def load_interactions_cbow(uci_data : pd.DataFrame):\n",
    "    interactions = {}\n",
    "    for line in uci_data.itertuples():\n",
    "        user_index, item_index, time = line[1], line[2], line[4]\n",
    "        interactions.setdefault(user_index, []).append((item_index, time))\n",
    "\n",
    "    interactions = {k : sorted(v, key = (lambda pair : pair[1])) for k, v in interactions.items()}\n",
    "    return {k : [x[0] for x in v] for k, v in interactions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_cbow(interactions : dict, window : int):\n",
    "    train_targets, train_contexts = [], []\n",
    "    test_targets, test_contexts = [], []\n",
    "\n",
    "    # Iterate through every interaction\n",
    "    for user_interactions in interactions.values():\n",
    "        num_interactions = len(user_interactions)\n",
    "        # Add to training data\n",
    "        for i in range(window, num_interactions - 1):\n",
    "            train_targets.append(user_interactions[i])\n",
    "            train_contexts.append([user_interactions[j] for j in np.arange(i - window, i)])\n",
    "        # Add to testing data\n",
    "        test_targets.append(user_interactions[num_interactions - 1])\n",
    "        test_contexts.append([user_interactions[j] for j \n",
    "            in np.arange(num_interactions - 1 - window, num_interactions - 1)])\n",
    "        \n",
    "    return train_targets, train_contexts, test_targets, test_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "window = 10\n",
    "\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "sorted_interactions = load_interactions_cbow(uci_data)\n",
    "train_targets, train_contexts, test_targets, test_contexts = train_test_uci_cbow(sorted_interactions, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and model\n",
    "ngrams_train = data.TensorDataset(torch.from_numpy(np.array(train_targets)), \n",
    "        torch.from_numpy(np.array(train_contexts)))\n",
    "ngrams_dataloader = data.DataLoader(dataset = ngrams_train, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "ngrams_test = data.TensorDataset(torch.from_numpy(np.array(test_targets)), \n",
    "    torch.from_numpy(np.array(test_contexts)))\n",
    "ngrams_dataloader_test = data.DataLoader(dataset = ngrams_test, batch_size = 1024, \n",
    "    shuffle = False, num_workers = 4)\n",
    "\n",
    "embedding_dim, num_epochs, learning_rate = 30, 10, 0.025\n",
    "loss = torch.nn.NLLLoss()\n",
    "cbow_net = word2vec.CBOW(num_items, embedding_dim, window)\n",
    "optimizer = optim.Adam(cbow_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0:\n",
      "\tloss = 0.00755936757408571\n",
      "\thit_rate = 0.0862533692722372\n",
      "\tauc = 0.7754174184573622\n",
      "Epoch 1:\n",
      "\tloss = 0.007325226632349235\n",
      "\thit_rate = 0.09198113207547169\n",
      "\tauc = 0.7689021135428201\n",
      "Epoch 2:\n",
      "\tloss = 0.007248465876323462\n",
      "\thit_rate = 0.09063342318059299\n",
      "\tauc = 0.7679007062788676\n",
      "Epoch 3:\n",
      "\tloss = 0.007186327703134198\n",
      "\thit_rate = 0.09669811320754718\n",
      "\tauc = 0.7717983458398955\n",
      "Epoch 4:\n",
      "\tloss = 0.0071348000401307175\n",
      "\thit_rate = 0.08861185983827494\n",
      "\tauc = 0.7654050001249921\n",
      "Epoch 5:\n",
      "\tloss = 0.007097633460257866\n",
      "\thit_rate = 0.08153638814016173\n",
      "\tauc = 0.7623120890884841\n",
      "Epoch 6:\n",
      "\tloss = 0.007075330726442584\n",
      "\thit_rate = 0.09501347708894879\n",
      "\tauc = 0.7655233749924638\n",
      "Epoch 7:\n",
      "\tloss = 0.00705237067514049\n",
      "\thit_rate = 0.09063342318059299\n",
      "\tauc = 0.7669026995351764\n",
      "Epoch 8:\n",
      "\tloss = 0.007035926035411229\n",
      "\thit_rate = 0.08018867924528301\n",
      "\tauc = 0.7519902234123431\n",
      "Epoch 9:\n",
      "\tloss = 0.007025862083110895\n",
      "\thit_rate = 0.0876010781671159\n",
      "\tauc = 0.7614172008240654\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_cbow = []\n",
    "auc_list_cbow = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    cbow_net.train()\n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_probabilities = cbow_net(contexts)\n",
    "\n",
    "        total_loss = loss(log_probabilities, targets)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, targets.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    cbow_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_cbow(cbow_net, test_targets, test_contexts, num_items)\n",
    "    hit_rate_list_cbow.append(hit_rate)\n",
    "    auc_list_cbow.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_cbow, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_cbow, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of CBOW\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Using a Naive Popularity Based System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Visualize the Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}