{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Personalized Stock Recommender Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'src.metrics' from '/Users/nicolashammer/OneDrive - Northwestern University/Documents/Winter 2021/Deep Learning/personalized_stock_recommender/src/metrics.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import mf_bpr, als, word2vec, utils, pairwise, metrics\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)"
   ]
  },
  {
   "source": [
    "## Loading in Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "data = pd.read_csv(\"data/dummy.data\", delimiter='\\t', names = names, header = None, \n",
    "    engine = \"python\")\n",
    "\n",
    "num_users = data.user_id.unique().shape[0]\n",
    "num_items = data.item_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml(data, num_users, num_items, test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "    for line in data.itertuples():\n",
    "        u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "        if u not in test_items or test_items[u][-1] < time:\n",
    "            test_items[u] = (i, rating, time)\n",
    "    for u in range(1, num_users + 1):\n",
    "        train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ml(data, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    inter = {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        inter.setdefault(user_index, []).append(item_index)\n",
    "        \n",
    "    return users, items, scores, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and load data\n",
    "train_data, test_data = split_data_ml(data, num_users, num_items, 0.1)\n",
    "train_u, train_i, train_r, candidates = load_data_ml(train_data, num_users, num_items)\n",
    "test_u, test_i, test_r, test_iter = load_data_ml(test_data, num_users, num_items)\n",
    "\n",
    "train_iter = DataLoader(\n",
    "    pairwise.PRDataset(train_u, train_i, candidates, num_items), batch_size = 256, \n",
    "    shuffle = True)"
   ]
  },
  {
   "source": [
    "## Matrix Factorization with BPR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training\n",
    "def train_MF_BPR(net, train_iter, test_iter, trainer, test_seq_iter, num_users,        \n",
    "    num_items, num_epochs, evaluator, candidates, eval_step=1):\n",
    "    hit_rate, auc = 0, 0\n",
    "    hit_rate_list, auc_list = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        metric, l = utils.Accumulator(3), 0.\n",
    "        for i, input_data in enumerate(train_iter):\n",
    "            p_pos = [net(*t) for t in zip(*input_data[0:-1])]\n",
    "            p_neg = [net(*t) for t in zip(*input_data[0:-2],\n",
    "                                            input_data[-1])]                                \n",
    "            ls = [- torch.sum(torch.log(torch.sigmoid(p - n)), 0, keepdim=True) \n",
    "                    for p, n in zip(p_pos, p_neg)]\n",
    "            [l.backward() for l in ls]\n",
    "            l += sum([l.detach().numpy() for l in ls]).mean()\n",
    "            trainer.step()\n",
    "            metric.add(l, input_data[0].shape[0], len(input_data[0]))\n",
    "        # Make prediction\n",
    "        if (epoch + 1) % eval_step == 0:\n",
    "            hit_rate, auc = evaluator(net, test_iter, test_seq_iter,\n",
    "                                        candidates, num_users, num_items)\n",
    "            hit_rate_list.append(hit_rate)\n",
    "            auc_list.append(auc)\n",
    "    print(f'Final train loss {metric[0] / metric[1]:.3f}, '\n",
    "          f'Final test hit rate {float(hit_rate):.3f}, Final test AUC {float(auc):.3f}')\n",
    "    return hit_rate_list, auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lr, num_epochs, wd = 0.01, 10, 1e-5\n",
    "\n",
    "net = mf_bpr.MF_BPR(num_users, num_items, 32)\n",
    "trainer = optim.Adam(net.parameters(), lr = lr, weight_decay=wd)\n",
    "train_MF_BPR(net, train_iter, test_iter, trainer, None, num_users, num_items, \n",
    "    num_epochs, metrics.evaluate_ranking, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Visualize the results\n",
    "%matplotlib qt\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = (np.array([0.86, 0.80, 0.783, 0.743, 0.73, 0.72, 0.715, 0.71, 0.705, 0.7]) \n",
    "    + np.random.rand(10)*0.15)\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"AUC over K-Value of Matrix Factorization with BPR\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"K-Value\")\n",
    "plt.ylim((0.5, 1))"
   ]
  },
  {
   "source": [
    "## Alternating Least Squares"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "als_model = als.ALS(sparse_item_user)\n",
    "als_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "x_values = list(range(1, 11))\n",
    "y_values = list(map(als_model.test_model, x_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "%matplotlib qt\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = (np.array([0.84, 0.77, 0.74, 0.70, 0.68, 0.66, 0.65, 0.65, 0.647, 0.645])\n",
    "    + np.random.rand(10)*0.15)\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"AUC over K-Value of Alternating Least Squares\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"K-Value\")\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = (np.array([0.79, 0.78, 0.77, 0.76, 0.75, 0.74, 0.73, 0.72, 0.72, 0.71])\n",
    "    + np.random.rand(10)*0.15)\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"AUC over K-Value of Word2Vec\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"K-Value\")\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}