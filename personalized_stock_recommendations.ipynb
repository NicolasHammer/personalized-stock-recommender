{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Personalized Stock Recommender Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Contents**\n",
    "RecSys for Banking and Financial Services\n",
    "\n",
    "1. Introduction\n",
    "2. Goal\n",
    "3. Drawbacks of Current Methods\n",
    "4. Datasets\n",
    "5. Method 1: Matrix Factorization with Bayesian Personalized Ranking\n",
    "6. Method 2: Alternating Least Squares\n",
    "7. Method 3: Word2Vec/CBOW\n",
    "\n",
    "Training and Evaluating RecSys Models\n",
    "\n",
    "1. Dummy Dataset\n",
    "2. Representative Dataset\n",
    "3. Examining the Transaction Results and Baseline Comparison\n",
    "\n",
    "Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# RecSys for Banking and Financial Services"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Introduction**\n",
    "Financial institutions are seriously looking to machine learning to provide tailored services and customized experiences to their customers.  Recommender systems (RecSys) are one class of algorithms to solve this problem.  These models are typically used in the realm of entertainment and e-commerce to recommend media or things to purchase, respectively. The paper [Recommender Systems for Banking and Financial Services](http://ceur-ws.org/Vol-1905/recsys2017_poster13.pdf) by Andrea Gigli, Fabrizio Lillo, and Daniele Regoli extends recommender systems to FinTech.\n",
    "\n",
    "My project is to replicate this paper to the best of my ability.  Despite not having the data the author's do, the replicated models which I produce perform quite well on the data I do have."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Goal**\n",
    "The question we are trying to answer is: given a portfolio of an investor's stocks, what stock is the investor most likely to invest in next?  This question has major applications to trading platforms like Fidelity and Robinhood, which could personalize recommendations to investors.\n",
    "<p align=\"center\">\n",
    "<br/><br/>\n",
    "<img src=\"images/goal.png\" alt = \"goal\" width=\"75%\"/>\n",
    "<br/><br/>\n",
    "</p>\n",
    "In the graphic above, we have an investor on the left who has invested in tech companies like IBM, Intel, AMD and Google, but not in automotive companies like ford.  This information is given to a model which then outputs a list of stocks which it believes the investor is most likely to purchase.  We see that NVIDIA and Apple are at the top while General Motors is quite low."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Drawbacks of Current Methods**\n",
    "Why is a new recommendation system needed, though, in the first place? Well, recommender systems in FinTech are relatively new, just becoming prevalent in the past five years or so:\n",
    "- Financial institutions still typically conduct their own research  and provide opinions to investors\n",
    "- At publication, many methods in the literature base their recommendations on broker research and news using NLP\n",
    "- These models take a long time to train and are costly\n",
    "\n",
    "Moreover, the literature tends towards explicit, un-personalized recommenders.  Explicit means that the information collected directly reflects explicit opinions of the investor.  Un-personalized means that the recommender provides the same recommendations to everyone, such as a popularity-based system.  Both of these things are unideal because explicit information is not always necessary and an un-personalized system is more disconnected from investors.  What we want is an implicit, personalized  recommender that is only given \"purchased\"/\"not purchased\" information.  This will lead to a happy investor and the firm implementing the recommender system to make more money, as illustrated in the graphic here. \n",
    "<p align=\"center\">\n",
    "    <img src=\"images/personalized.png\" alt = \"personalized\" width=\"50%\"/>\n",
    "    <br/><br/>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Recommender Systems to the Rescue**\n",
    "At the 2017 ACM Recommender Systems conference, Gigli, Lillo, and Regoli showed that an *implicit* recommender system can predict preferences of users (investors) and the items (stocks) they purchase.  The showcased three different RecSys methods:\n",
    "- Matrix factorization with Bayesian Personalized Ranking (BPR)\n",
    "- Alternating Least Squares (ALS)\n",
    "- Word2Vec/Continuous Bag of Words\n",
    "\n",
    "The paper compares these algorithms against popularity methods that base their predictions solely on the popularity of different items (completely unpersonalized). \n",
    "<p align=\"center\">\n",
    "<br/><br/>\n",
    "<img src=\"images/recsys_poster.png\" alt = \"recsys_poster\" width=\"66%\"/>\n",
    "<br/><br/>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Datasets**\n",
    "The data used for these recommendation systems is an interaction matrix between investors and the stocks they purchase.  More specificaly, we need a relation where each record is a transaction that has\n",
    "- the investor identification number (```int```)\n",
    "- the stock identification number (```int```)\n",
    "- the timestamp of that transaction (```int```)\n",
    "\n",
    "The interactions matrix itself should end up boiling down to somelike like the table below.\n",
    "<p align=\"center\">\n",
    "<br/><br/>\n",
    "<img src=\"images/desired_data.png\" alt = \"desired_data\" width=\"66%\"/>\n",
    "<br/><br/>\n",
    "</p>\n",
    "\n",
    "### **Ideal Data**\n",
    "The authors of the paper obtain this data from a European bank, where about 200,000 clients make 1.3 million transaction total.  Unfortunately, this data is proprietary and not available to us.  In this data's stead, we use two other datasets: a dummy dataset for testing the model and a representative dataset of transactions collected from UC Irvine.\n",
    "\n",
    "### **Dummy Data**\n",
    "To test to see if our model works, we will use the [MovieLens 100k](https://grouplens.org/datasets/movielens/100k/) dataset.  This dataset contains 100,000 records of about 1,000 different users each interacting with, on average, 100 movies from a population of 1,600 movies.  So, our interaction matrix will have a shape of approximately 1,000 rows by 1,600 columns.\n",
    "\n",
    "### **Representative Dataset**\n",
    "Orginially, I was going to use 13F forms submitted by hedge funds in Q4 2020 instead of users/stocks; however, the thousands of hedge funds I looked at invested from too large of a popultion of stocks.  This resulted in the interaction matrix becoming too scarce to make meaningful predictions.  Time permitting, I would like to continue to work towards using 13F forms, as my models were effective when using a small subset of hedge funds with similar investment strategies.\n",
    "\n",
    "Instead, per the TA's permission, I will use a synthetic, representative dataset of individual transactions from [UC Irvine](https://archive.ics.uci.edu/ml/datasets/online+retail).  This dataset contains approximately 540,000 records.\n",
    "<br/><br/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## **Method 1: Matrix Factorization with BPR [(Rendle et al., 2012)](https://arxiv.org/pdf/1205.2618.pdf)**\n",
    "Matrix factorization (MF) is used because it captures the low-rank structure of linear investor-stock interactions.  In the figure below, we let $m, n, k \\in \\mathbb{N}$, where $m$ is the number of investors, $n$ is the number of stocks, and $k$ is the number of latent factors in $P$ and $Q$.\n",
    "<p align=\"center\">\n",
    "<img src=\"images/matrix_factorization.png\" alt = \"matrix_factorization\" width=\"66%\"/>\n",
    "<br/><br/>\n",
    "</p>\n",
    "\n",
    "The general model of MF is that there is an investor/stock interaction matrix $R$ which can be broken down into two latent matrices $P$ and $Q$.  MF finds these latent matrices using mean squared error and an optimizer such as Adam and uses it to predict unknown ratings.  However, in our case, since we are using *implicit* information, it is imperative that we use an optimization criterion such as Bayesian Personalized Ranking (BPR) over pairs of stocks for a particular investor when updating our model's parameters.  In this implicit scenario, the mulitplication of $P$ and $Q$ won't result in an explicit reconstruction of $R$, but rather a list of scores for each stock which we can then use to rank preferences.\n",
    "\n",
    "To illustrate BPR, first let $I$ denote all stocks and $I^+$ denote purchased stocks.  Then, BPR is defined for pairs of stocks (per investor $u$) in the set\n",
    "$$D:=\\{(u, i, j)\\ |\\ i \\in I_{u}^{+} \\wedge j \\in I \\setminus I_{u}^{+} \\}$$\n",
    "Let's further define $\\hat{y}$ as the binary prediction of \"purchased\" (1) or \"not purchased\" (0), $\\lambda$ as the regularization hyperparameter, and $\\Theta$ as the learned parameters.  Then BPR loss with L2-regularization is defined to be\n",
    "$$\\text{BPRLoss} := \\sum_{u, i, j \\in D}\\ln(\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) - \\lambda_\\Theta ||\\Theta||^2$$\n",
    "where $\\sigma$ is the sigmoid function.\n",
    "<br/><br/>\n",
    "\n",
    "### **Model Implementation in PyTorch**\n",
    "The above logic is written in PyTorch in the file [mf_bpr.py](src/mf_bpr.py).  We first start with the model itself, which has two embeddings matrices as defined using ```nn.Embedding``` and then initialized via a normal distribution.  During the forward propagation step, ids corresponding to the investor and ids of the stocks they purchased are supplied.  The embeddings of these ids are obtained and the dot product of them are multiplied together to compute the scores.\n",
    "\n",
    "```python\n",
    "class MF_BPR(nn.Module):\n",
    "    def __init__(self, investor_num: int, stock_num: int, latent_factors: int):\n",
    "        \"\"\"\n",
    "        Initializes a matrix factorization model that is meant to be used in\n",
    "        conjunction with Bayesian Personalized Recommendation loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        investor_num (int) - number of investors\\n\n",
    "        stock_num (int) - number of stocks\\n\n",
    "        latent_factors (int) - number of latent factors\n",
    "        \"\"\"\n",
    "        super(MF_BPR, self).__init__()\n",
    "        self.embed_investor = nn.Embedding(investor_num, latent_factors)\n",
    "        self.embed_stock = nn.Embedding(stock_num, latent_factors)\n",
    "\n",
    "        nn.init.normal_(self.embed_investor.weight, std=0.01)\n",
    "        nn.init.normal_(self.embed_stock.weight, std=0.01)\n",
    "\n",
    "    def forward(self, investors: torch.Tensor, stocks: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        investors (torch.Tensor) - investor ids\\n\n",
    "        stocks (torch.Tensor) - ids of stocks that the investors purchased\\n\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        scores  (torch.Tensor) - scores of stocks that the investors may purchase next\n",
    "        \"\"\"\n",
    "        investor = self.embed_investor(investors)\n",
    "        stock_positive = self.embed_stock(stocks)\n",
    "        scores = (investor * stock_positive).sum(dim=-1)\n",
    "\n",
    "        return scores\n",
    "```\n",
    "The Bayesian Personalized ranking loss which accompanies the loss is constructed outside of the class.  Given score tensors of (investors, num_stocks), we aim to maximize the distance between the positive and negative scores:\n",
    "```python\n",
    "def BPR_Loss(positive : torch.Tensor, negative : torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given postive and negative examples, compute Bayesian Personalized ranking loss\n",
    "    \"\"\"\n",
    "    distances = positive - negative\n",
    "    loss = - torch.sum(torch.log(torch.sigmoid(distances)), 0, keepdim=True)\n",
    "\n",
    "    return loss\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from src import mf_bpr, als, word2vec, metrics, datasets, utils"
   ]
  },
  {
   "source": [
    "## Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_dummy():\n",
    "    dummy_data = pd.read_csv(\"data/dummy.data\", sep='\\t', names = ['user_id', 'item_id',\n",
    "        'rating', 'timestamp'], engine = \"python\")\n",
    "    num_users = dummy_data.user_id.unique().shape[0]\n",
    "    num_items = dummy_data.item_id.unique().shape[0]\n",
    "    return dummy_data, num_users, num_items"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_uci():\n",
    "    # Read data\n",
    "    uci_data = pd.read_excel(\"data/data_UCI.xlsx\", header = 0, engine = \"openpyxl\")\n",
    "\n",
    "    # Massage data\n",
    "    uci_data = uci_data[pd.isnull(uci_data[\"investor_id\"]) == False]\n",
    "    uci_data = uci_data.drop_duplicates(subset = [\"investor_id\", \"stock_id\"])\n",
    "\n",
    "    v = uci_data[\"investor_id\"].value_counts()\n",
    "    uci_data = uci_data[uci_data[\"investor_id\"].isin(v.index[v.gt(20)])]\n",
    "\n",
    "    uci_data[\"investor_id\"], _ = pd.factorize(uci_data[\"investor_id\"])\n",
    "    uci_data[\"stock_id\"], _ = pd.factorize(uci_data[\"stock_id\"])\n",
    "\n",
    "    num_investors = uci_data.investor_id.unique().shape[0]\n",
    "    num_stocks = uci_data.stock_id.unique().shape[0]\n",
    "    return uci_data, num_investors, num_stocks"
   ]
  },
  {
   "source": [
    "## Matrix Factorization with BPR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_bpr(net, test_input, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "        test_dataset = data.TensorDataset(torch.from_numpy(np.array(user_ids)),    \n",
    "            torch.from_numpy(np.array(item_ids)))\n",
    "        test_data_iter = data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "\n",
    "        for _, (user_idxs, item_idxs) in enumerate(test_data_iter):\n",
    "            scores.extend(list(net(user_idxs, item_idxs).detach().numpy()))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "        temp = metrics.hit_and_auc(ranked_items[u], test_input[u][0], 100)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "#### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_bpr(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "        if u not in test_items or test_items[u][2] < time:\n",
    "            test_items[u] = (i, rating, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(1, num_users + 1):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[3])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_dummy_bpr(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "train_dummy, test_dummy = train_test_dummy_bpr(dummy_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_dummy_bpr(train_dummy,    \n",
    "    num_users, num_items)\n",
    "train_dummy_dataset = datasets.PairwiseDataset(np.array(train_users), np.array(train_items),\n",
    "    interactions, num_items)\n",
    "train_dataloader = data.DataLoader(dataset = train_dummy_dataset, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_dummy_bpr(test_dummy, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd, latent_factors = 0.01, 20, 1e-5, 10\n",
    "\n",
    "bpr_net = mf_bpr.MF_BPR(num_users, num_items, latent_factors) \n",
    "loss = mf_bpr.BPR_Loss\n",
    "optimizer = optim.Adam(bpr_net.parameters(), lr = 0.01, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_bpr_dummy = []\n",
    "auc_list_bpr_dummy = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    bpr_net.train()\n",
    "    for i, (user_idxs, item_idxs, neg_items) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p_pos = bpr_net(user_idxs, item_idxs)\n",
    "        p_neg = bpr_net(user_idxs, neg_items)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    bpr_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(bpr_net, test_interactions, interactions, num_users,   \n",
    "        num_items)\n",
    "    hit_rate_list_bpr_dummy.append(hit_rate)\n",
    "    auc_list_bpr_dummy.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_bpr_dummy, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_bpr_dummy, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of MF\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_bpr(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, time = line[1], line[2], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, time))\n",
    "        if u not in test_items or test_items[u][1] < time:\n",
    "            test_items[u] = (i, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(0, num_users):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[2])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_uci_bpr(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = line[1], line[2]\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready uci data\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "train_uci, test_uci = train_test_uci_bpr(uci_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_uci_bpr(train_uci,    \n",
    "    num_users, num_items)\n",
    "train_uci_dataset = datasets.PairwiseDataset(np.array(train_users), np.array(train_items),\n",
    "    interactions, num_items)\n",
    "train_dataloader = data.DataLoader(dataset = train_uci_dataset, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_uci_bpr(test_uci, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd, latent_factors = 0.01, 10, 1e-5, 10\n",
    "\n",
    "bpr_net = mf_bpr.MF_BPR(num_users, num_items, latent_factors) \n",
    "loss = mf_bpr.BPR_Loss\n",
    "optimizer = optim.Adam(bpr_net.parameters(), lr = 0.01, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_bpr_uci = []\n",
    "auc_list_bpr_uci = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    bpr_net.train()\n",
    "    for i, (user_idxs, item_idxs, neg_items) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p_pos = bpr_net(user_idxs, item_idxs)\n",
    "        p_neg = bpr_net(user_idxs, neg_items)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    bpr_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(bpr_net, test_interactions, interactions, num_users,   \n",
    "        num_items)\n",
    "    hit_rate_list_bpr_uci.append(hit_rate)\n",
    "    auc_list_bpr_uci.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_bpr_uci, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_bpr_uci, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of MF\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Alternating Least Squares"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_als(net, test_input, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "\n",
    "        scores.extend(list(net.predict(user_ids, item_ids)))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "        temp = metrics.hit_and_auc(ranked_items[u], test_input[u][0], 100)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_als(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "        if u not in test_items or test_items[u][2] < time:\n",
    "            test_items[u] = (i, rating, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(1, num_users + 1):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[3])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user and item indices (zero based) and scores \n",
    "def load_dummy_als(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready dummy data\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "train_dummy, test_dummy = train_test_dummy_als(dummy_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_dummy_als(train_dummy,    \n",
    "    num_users, num_items)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_dummy_als(test_dummy, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_epochs, reg, latent_factors = 20, 0.01, 30\n",
    "\n",
    "ratings_matrix = coo_matrix((train_ratings, (train_users, train_items)), shape = (num_users, \n",
    "    num_items)).todense()\n",
    "als_net = als.ALS(num_users, num_items, latent_factors, ratings_matrix, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_als_dummy = []\n",
    "auc_list_als_dummy = []\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    # Train with entire batch\n",
    "    als_net.train()\n",
    "\n",
    "    # Evaluate\n",
    "    hit_rate, auc = evaluate_ranking_als(als_net, test_interactions, interactions, num_users,\n",
    "        num_items)\n",
    "    hit_rate_list_als_dummy.append(hit_rate)\n",
    "    auc_list_als_dummy.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: hit_rate = {hit_rate}, auc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_als_dummy, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_als_dummy, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of ALS\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_als(dummy_data : pd.DataFrame, num_users : int, num_items : int):\n",
    "    train_items, test_items, train_list = {}, {}, []\n",
    "\n",
    "    # Iterate through every line in the raw data\n",
    "    for line in dummy_data.itertuples():\n",
    "        u, i, time = line[1], line[2], line[4]\n",
    "        train_items.setdefault(u, []).append((u, i, time))\n",
    "        if u not in test_items or test_items[u][1] < time:\n",
    "            test_items[u] = (i, time)\n",
    "        \n",
    "    # Iterate through every user and add their samples, sorted by timestamp, to the train \n",
    "    # list\n",
    "    for u in range(0, num_users):\n",
    "        train_list.extend(sorted(train_items[u], key = (lambda x : x[2])))\n",
    "\n",
    "    test_data = [(key, *value) for key, value in test_items.items()]\n",
    "\n",
    "    train_data = [item for item in train_list if item not in test_data]\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uci_als(dummy, num_users, num_items):\n",
    "    users, items, scores = [], [], []\n",
    "    interactions = {}\n",
    "    for line in dummy.itertuples():\n",
    "        user_index, item_index = line[1], line[2]\n",
    "        score = 1 # implicit\n",
    "\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "\n",
    "        interactions.setdefault(user_index, []).append(item_index)\n",
    "\n",
    "    return users, items, scores, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready uci data\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "train_uci, test_uci = train_test_uci_als(uci_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "train_users, train_items, train_ratings, interactions = load_uci_als(train_uci,    \n",
    "    num_users, num_items)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = load_uci_als(test_uci, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_epochs, reg, latent_factors = 10, 0.01, 30\n",
    "\n",
    "ratings_matrix = coo_matrix((train_ratings, (train_users, train_items)), shape = (num_users, \n",
    "    num_items)).todense()\n",
    "als_net = als.ALS(num_users, num_items, latent_factors, ratings_matrix, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_als_uci = []\n",
    "auc_list_als_uci = []\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    # Train with entire batch\n",
    "    als_net.train()\n",
    "\n",
    "    # Evaluate\n",
    "    hit_rate, auc = evaluate_ranking_als(als_net, test_interactions, interactions, num_users,\n",
    "        num_items)\n",
    "    hit_rate_list_als_uci.append(hit_rate)\n",
    "    auc_list_als_uci.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: hit_rate = {hit_rate}, auc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_als_uci, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_als_uci, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of ALS\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_cbow(net, test_targets, test_contexts, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    item_ids = list(range(num_items))\n",
    "    \n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader_test):\n",
    "        scores = net(contexts).tolist()\n",
    "        for u, row in enumerate(scores):\n",
    "            item_scores = list(zip(item_ids, row))\n",
    "            ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "            ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "            temp = metrics.hit_and_auc(ranked_items[u], test_targets[u], 100)\n",
    "            hit_rate.append(temp[0])\n",
    "            auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "source": [
    "### Dummy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep interactions\n",
    "def load_interactions_cbow(dummy_data : pd.DataFrame):\n",
    "    interactions = {}\n",
    "    for line in dummy_data.itertuples():\n",
    "        user_index, item_index, time = line[1] - 1, line[2] - 1, line[4]\n",
    "        interactions.setdefault(user_index, []).append((item_index, time))\n",
    "\n",
    "    interactions = {k : sorted(v, key = (lambda pair : pair[1])) for k, v in interactions.items()}\n",
    "    return {k : [x[0] for x in v] for k, v in interactions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_dummy_cbow(interactions : dict, window : int):\n",
    "    train_targets, train_contexts = [], []\n",
    "    test_targets, test_contexts = [], []\n",
    "\n",
    "    # Iterate through every interaction\n",
    "    for user_interactions in interactions.values():\n",
    "        num_interactions = len(user_interactions)\n",
    "        # Add to training data\n",
    "        for i in range(window, num_interactions - 1):\n",
    "            train_targets.append(user_interactions[i])\n",
    "            train_contexts.append([user_interactions[j] for j in np.arange(i - window, i)])\n",
    "        # Add to testing data\n",
    "        test_targets.append(user_interactions[num_interactions - 1])\n",
    "        test_contexts.append([user_interactions[j] for j \n",
    "            in np.arange(num_interactions - 1 - window, num_interactions - 1)])\n",
    "        \n",
    "    return train_targets, train_contexts, test_targets, test_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "window = 10\n",
    "\n",
    "dummy_data, num_users, num_items = read_dummy()\n",
    "sorted_interactions = load_interactions_cbow(dummy_data)\n",
    "train_targets, train_contexts, test_targets, test_contexts = train_test_dummy_cbow(sorted_interactions, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and model\n",
    "ngrams_train = data.TensorDataset(torch.from_numpy(np.array(train_targets)), \n",
    "        torch.from_numpy(np.array(train_contexts)))\n",
    "ngrams_dataloader = data.DataLoader(dataset = ngrams_train, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "ngrams_test = data.TensorDataset(torch.from_numpy(np.array(test_targets)), \n",
    "    torch.from_numpy(np.array(test_contexts)))\n",
    "ngrams_dataloader_test = data.DataLoader(dataset = ngrams_test, batch_size = 1024, \n",
    "    shuffle = False, num_workers = 4)\n",
    "\n",
    "embedding_dim, num_epochs, learning_rate = 30, 20, 0.025\n",
    "loss = torch.nn.NLLLoss()\n",
    "cbow_net = word2vec.CBOW(num_items, embedding_dim, window)\n",
    "optimizer = optim.Adam(cbow_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_cbow_dummy = []\n",
    "auc_list_cbow_dummy = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    cbow_net.train()\n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_probabilities = cbow_net(contexts)\n",
    "\n",
    "        total_loss = loss(log_probabilities, targets)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, targets.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    cbow_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_cbow(cbow_net, test_targets, test_contexts, num_items)\n",
    "    hit_rate_list_cbow_dummy.append(hit_rate)\n",
    "    auc_list_cbow_dummy.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_cbow_dummy, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_cbow_dummy, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of CBOW\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "### Representative UCI Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep interactions\n",
    "def load_interactions_cbow(uci_data : pd.DataFrame):\n",
    "    interactions = {}\n",
    "    for line in uci_data.itertuples():\n",
    "        user_index, item_index, time = line[1], line[2], line[4]\n",
    "        interactions.setdefault(user_index, []).append((item_index, time))\n",
    "\n",
    "    interactions = {k : sorted(v, key = (lambda pair : pair[1])) for k, v in interactions.items()}\n",
    "    return {k : [x[0] for x in v] for k, v in interactions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_uci_cbow(interactions : dict, window : int):\n",
    "    train_targets, train_contexts = [], []\n",
    "    test_targets, test_contexts = [], []\n",
    "\n",
    "    # Iterate through every interaction\n",
    "    for user_interactions in interactions.values():\n",
    "        num_interactions = len(user_interactions)\n",
    "        # Add to training data\n",
    "        for i in range(window, num_interactions - 1):\n",
    "            train_targets.append(user_interactions[i])\n",
    "            train_contexts.append([user_interactions[j] for j in np.arange(i - window, i)])\n",
    "        # Add to testing data\n",
    "        test_targets.append(user_interactions[num_interactions - 1])\n",
    "        test_contexts.append([user_interactions[j] for j \n",
    "            in np.arange(num_interactions - 1 - window, num_interactions - 1)])\n",
    "        \n",
    "    return train_targets, train_contexts, test_targets, test_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "window = 10\n",
    "\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "sorted_interactions = load_interactions_cbow(uci_data)\n",
    "train_targets, train_contexts, test_targets, test_contexts = train_test_uci_cbow(sorted_interactions, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and model\n",
    "ngrams_train = data.TensorDataset(torch.from_numpy(np.array(train_targets)), \n",
    "        torch.from_numpy(np.array(train_contexts)))\n",
    "ngrams_dataloader = data.DataLoader(dataset = ngrams_train, batch_size = 1024, \n",
    "    shuffle = True, num_workers = 4)\n",
    "ngrams_test = data.TensorDataset(torch.from_numpy(np.array(test_targets)), \n",
    "    torch.from_numpy(np.array(test_contexts)))\n",
    "ngrams_dataloader_test = data.DataLoader(dataset = ngrams_test, batch_size = 1024, \n",
    "    shuffle = False, num_workers = 4)\n",
    "\n",
    "embedding_dim, num_epochs, learning_rate = 30, 10, 0.025\n",
    "loss = torch.nn.NLLLoss()\n",
    "cbow_net = word2vec.CBOW(num_items, embedding_dim, window)\n",
    "optimizer = optim.Adam(cbow_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list_cbow_uci = []\n",
    "auc_list_cbow_uci = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    cbow_net.train()\n",
    "    for _, (targets, contexts) in enumerate(ngrams_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_probabilities = cbow_net(contexts)\n",
    "\n",
    "        total_loss = loss(log_probabilities, targets)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, targets.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    cbow_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_cbow(cbow_net, test_targets, test_contexts, num_items)\n",
    "    hit_rate_list_cbow_uci.append(hit_rate)\n",
    "    auc_list_cbow_uci.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list_cbow_uci, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list_cbow_uci, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of CBOW\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Using a Naive Popularity Based System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready uci data\n",
    "train_test_uci_pop = train_test_uci_bpr\n",
    "load_uci_bpr = load_uci_bpr\n",
    "\n",
    "uci_data, num_users, num_items = read_uci()\n",
    "train_uci, test_uci = train_test_uci_bpr(uci_data, num_users, num_items)\n",
    "\n",
    "# Training data\n",
    "_, train_items, _, _ = load_uci_bpr(train_uci,    \n",
    "    num_users, num_items)\n",
    "\n",
    "# Test data\n",
    "_, test_items, _, _ = load_uci_bpr(test_uci, \n",
    "    num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute hitting rate and AUC\n",
    "import collections\n",
    "\n",
    "hit_rate_pop = []\n",
    "auc_list_pop = []\n",
    "ranked_list = list(collections.Counter(train_items).keys())\n",
    "for u in range(num_users):\n",
    "    temp = metrics.hit_and_auc(ranked_list, test_items[u], 100)\n",
    "    hit_rate_pop.append(temp[0])\n",
    "    auc_list_pop.append(temp[1])\n",
    "hit_rate_pop_avg = sum(hit_rate_pop)/len(hit_rate_pop)\n",
    "auc_pop_avg = sum(auc_list_pop)/len(auc_list_pop)"
   ]
  },
  {
   "source": [
    "## Visualize the Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Plot\n",
    "x = list(range(1, num_epochs + 1))\n",
    "\n",
    "plt.plot(x, auc_list_bpr_uci, label = \"MF_BPR\")\n",
    "plt.plot(x, auc_list_als_uci, label = \"ALS\")\n",
    "plt.plot(x, auc_list_cbow_uci, label = \"CBOW\")\n",
    "plt.plot([1, 10], [auc_pop_avg, auc_pop_avg], label = \"POP.u\", color = \"grey\", alpha = 0.5, linestyle = \"dashed\")\n",
    "\n",
    "plt.title(\"AUC over Epoch for All Algorithms\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.ylim((0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitting Rate Plot\n",
    "x = list(range(1, num_epochs + 1))\n",
    "\n",
    "plt.plot(x, hit_rate_list_bpr_uci, label = \"MF_BPR\")\n",
    "plt.plot(x, hit_rate_list_als_uci, label = \"ALS\")\n",
    "plt.plot(x, hit_rate_list_cbow_uci, label = \"CBOW\")\n",
    "plt.plot([1, 10], [hit_rate_pop_avg, hit_rate_pop_avg], label = \"POP.u\", color = \"grey\", alpha = 0.5, linestyle = \"dashed\")\n",
    "\n",
    "plt.title(\"Hitting Rate over Epoch for All Algorithms\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Hitting Rate\")\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}